{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5dfb1-fbeb-4d63-8d9a-ca5569a4271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Используйте набор данных California Housing, чтобы сравнить эффективность линейной регрессии и деревьев решений при прогнозировании цен на жилье."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bed62af-b49e-412f-83dc-5d35c5ee4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06a1d9bf-b3fc-444a-a2f2-844a393b902e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data':        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       " 0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       " 1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       " 2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       " 3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       " 4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       " ...       ...       ...       ...        ...         ...       ...       ...   \n",
       " 20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       " 20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       " 20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       " 20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       " 20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       " \n",
       "        Longitude  \n",
       " 0        -122.23  \n",
       " 1        -122.22  \n",
       " 2        -122.24  \n",
       " 3        -122.25  \n",
       " 4        -122.25  \n",
       " ...          ...  \n",
       " 20635    -121.09  \n",
       " 20636    -121.21  \n",
       " 20637    -121.22  \n",
       " 20638    -121.32  \n",
       " 20639    -121.24  \n",
       " \n",
       " [20640 rows x 8 columns],\n",
       " 'target': 0        4.526\n",
       " 1        3.585\n",
       " 2        3.521\n",
       " 3        3.413\n",
       " 4        3.422\n",
       "          ...  \n",
       " 20635    0.781\n",
       " 20636    0.771\n",
       " 20637    0.923\n",
       " 20638    0.847\n",
       " 20639    0.894\n",
       " Name: MedHouseVal, Length: 20640, dtype: float64,\n",
       " 'frame':        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       " 0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       " 1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       " 2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       " 3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       " 4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       " ...       ...       ...       ...        ...         ...       ...       ...   \n",
       " 20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       " 20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       " 20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       " 20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       " 20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       " \n",
       "        Longitude  MedHouseVal  \n",
       " 0        -122.23        4.526  \n",
       " 1        -122.22        3.585  \n",
       " 2        -122.24        3.521  \n",
       " 3        -122.25        3.413  \n",
       " 4        -122.25        3.422  \n",
       " ...          ...          ...  \n",
       " 20635    -121.09        0.781  \n",
       " 20636    -121.21        0.771  \n",
       " 20637    -121.22        0.923  \n",
       " 20638    -121.32        0.847  \n",
       " 20639    -121.24        0.894  \n",
       " \n",
       " [20640 rows x 9 columns],\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. rubric:: References\\n\\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n  Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house = fetch_california_housing(as_frame=True)\n",
    "house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "933e5b40-a909-45a3-9004-99c07ca11c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Linear Regression: 0.555891598695244\n",
      "R-squared for Linear Regression: 0.5757877060324511\n",
      "\n",
      "Mean Squared Error for Decision Tree: 0.4834738633033672\n",
      "R-squared for Decision Tree 0.6310511669781252\n"
     ]
    }
   ],
   "source": [
    "# Определяем переменные предиктора (X) и отклика (y)\n",
    "X, y = house.data, house.target\n",
    "\n",
    "# Разделите данные на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Инициализируем модель линейной регрессии\n",
    "model_lin = LinearRegression()\n",
    "# Обучаем модель на обучающих данных\n",
    "model_lin.fit(X_train, y_train)\n",
    "\n",
    "# Делаем прогнозы на тестовом наборе\n",
    "y_pred_lin = model_lin.predict(X_test)\n",
    "# Рассчитайте метрики оценки\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "r2_lin = r2_score(y_test, y_pred_lin)\n",
    "\n",
    "model_tree = DecisionTreeRegressor()   \n",
    "model_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree = model_tree.predict(X_test)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "\n",
    "print(f\"Mean Squared Error for Linear Regression: {mse_lin}\")\n",
    "print(f\"R-squared for Linear Regression: {r2_lin}\\n\")\n",
    "\n",
    "print(f\"Mean Squared Error for Decision Tree: {mse_tree}\")\n",
    "print(f\"R-squared for Decision Tree {r2_tree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f8de7-3491-4aeb-bacf-95937f02381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Дерево решений немного лучше предсказывает цены, но незначительно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c9d2a-232a-4ba9-b4c8-b9494ddf12ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Используйте набор данных Wine, чтобы предсказать качество вина на основе его химических свойств. Выберите две модели из пройденных и сравните их эффективность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccc6e463-aa89-4633-aa37-ef711dc0e334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0       0  \n",
       "1                            3.40   1050.0       0  \n",
       "2                            3.17   1185.0       0  \n",
       "3                            3.45   1480.0       0  \n",
       "4                            2.93    735.0       0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0       2  \n",
       "174                          1.56    750.0       2  \n",
       "175                          1.56    835.0       2  \n",
       "176                          1.62    840.0       2  \n",
       "177                          1.60    560.0       2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "wine = load_wine()\n",
    "df_wine = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df_wine['target'] = wine.target\n",
    "df_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ec8f86-a8b7-452f-8ce0-ca0c22cc2831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9444444444444444\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.88      1.00      0.93        14\n",
      "           2       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "Decision Tree Classifier Accuracy: 0.9722222222222222\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_wine[['alcohol', \n",
    "             'malic_acid', \n",
    "             'ash', \n",
    "             'alcalinity_of_ash',\n",
    "             'magnesium',\t\n",
    "             'total_phenols',\t\n",
    "             'flavanoids',\t\n",
    "             'nonflavanoid_phenols',\t\n",
    "             'proanthocyanins',\t\n",
    "             'color_intensity',\t\n",
    "             'hue',\t\n",
    "             'od280/od315_of_diluted_wines',\t\n",
    "             'proline']]\t\n",
    "\n",
    "y = df_wine['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model_log = LogisticRegression(max_iter=5000)\n",
    "model_log.fit(X_train, y_train)\n",
    "y_pred_log = model_log.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_log)\n",
    "class_report = classification_report(y_test, y_pred_log)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Отчет о классификации\n",
    "print(\"Classification report:\")\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "model_tree_c = DecisionTreeClassifier()\n",
    "model_tree_c.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree_c = model_tree_c.predict(X_test)\n",
    "\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree_c)\n",
    "class_report_tree = classification_report(y_test, y_pred_tree_c)\n",
    "\n",
    "print(\"Decision Tree Classifier Accuracy:\", accuracy_tree)\n",
    "print(\"Classification report:\")\n",
    "print(class_report_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12521df1-0829-422f-a345-c446dd57615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Обе модели показывают хорошие результаты, но дерево определяет чуть лучше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
